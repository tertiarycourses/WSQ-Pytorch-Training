{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learner/Faciliator Guide - WSQ - Predictive Modelling with Pytorch",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBmwaDOqvU_-"
      },
      "source": [
        "# Topic 1 Overview of Deep Learning and Pytorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZd_A2zLHqjH"
      },
      "source": [
        "## Install Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff1cJre4vME_"
      },
      "source": [
        "!pip3 install torch torchvision torchaudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2UwZR6jvONy"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovMIm1O4vPky"
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxDOnc69vRTn"
      },
      "source": [
        "print(\"Cuda Current Device: \", torch.cuda.current_device())\n",
        "print(\"Cude Device Count: \", torch.cuda.device_count())\n",
        "print(\"Cude Device Name: \", torch.cuda.get_device_name(0))\n",
        "print(\"Cude Device Available : \", torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KufJMtkSCAnx"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTXm_2dZh63x"
      },
      "source": [
        "## Basic Pytorch Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj5zdxGUf6IH"
      },
      "source": [
        "# Create a Torch Vector\n",
        "a = [1, 2, 3]\n",
        "b = torch.Tensor(a)\n",
        "# b = torch.FloatTensor(a)\n",
        "# b = torch.DoubleTensor(a)\n",
        "# b = torch.IntTensor(a)\n",
        "# b = torch.LongTensor(a)\n",
        "print(b)\n",
        "print(b[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXQCPOCAf-i_"
      },
      "source": [
        "# Create a Torch Matrix\n",
        "a = [[1, 2, 3], [4, 5, 6]]\n",
        "b = torch.Tensor(a)\n",
        "print(b)\n",
        "print(b[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XN85oeHgBb6"
      },
      "source": [
        "# Create a 3D Tensor\n",
        "a = [[[1., 2.], [3., 4.]],\n",
        "     [[5., 6.], [7., 8.]]]\n",
        "b = torch.Tensor(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yOsyKiSgE3e"
      },
      "source": [
        "# Conversion from Tensor to numpy\n",
        "a = torch.Tensor([3])\n",
        "print(a)\n",
        "b = a.numpy()\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jHE-i1znl7H"
      },
      "source": [
        "# Conversion from numpy to Tensor\n",
        "import numpy as np\n",
        "a = np.arange(6).reshape(2,3)\n",
        "print(a)\n",
        "b = torch.from_numpy(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzDb1BOehNoG"
      },
      "source": [
        "# Numpy functions\n",
        "a = [1,2,3,4]\n",
        "a_np = np.sum(a)\n",
        "a_np = np.mean(a)\n",
        "print(a_np)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2u2QLZnhXa6"
      },
      "source": [
        "# Torch functions\n",
        "b = torch.Tensor(a)\n",
        "b_t = torch.sum(b)\n",
        "b_t = torch.mean(b)\n",
        "b_t = torch.max(b)\n",
        "print(b_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmI9Q9Ghh0my"
      },
      "source": [
        "# Tensor operations\n",
        "a = torch.Tensor([1,1])\n",
        "b = torch.Tensor([2,2])\n",
        "print(a+b)\n",
        "print(torch.add(a, b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJCTD-SYbDy8"
      },
      "source": [
        "# Tensor operations with GPU\n",
        "a = torch.Tensor([1,1]).to(device)\n",
        "b = torch.Tensor([2,2]).to(device)\n",
        "c = a+b\n",
        "print(c)\n",
        "print(c.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRYeznRviUw0"
      },
      "source": [
        "# Activity: Tensor Operation with GPU\n",
        "a = torch.Tensor([3]).to(device)\n",
        "b = torch.Tensor([4]).to(device)\n",
        "c = torch.Tensor([5]).to(device)\n",
        "d = a*b+c\n",
        "print(d)\n",
        "print(d.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6332HGEhcqc"
      },
      "source": [
        "# Torch matrix multiplication\n",
        "mat1 = torch.randn(2, 3)\n",
        "mat2 = torch.randn(3, 3)\n",
        "torch.mm(mat1, mat2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbdW_-ZSZtbQ"
      },
      "source": [
        "# Activity: Matrix operation\n",
        "x = torch.Tensor([[1,1]])\n",
        "w = torch.Tensor([[1,2],[3,4]])\n",
        "b = torch.Tensor([[2,2]])\n",
        "print(torch.mm(x,w)+b)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHLAtiyihloR"
      },
      "source": [
        "# Generate Special Torch Tensors\n",
        "a = torch.diag(torch.Tensor([1,2,3]))\n",
        "a = torch.eye(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsS5foAshq1P"
      },
      "source": [
        "# Torch linspace\n",
        "a_np = np.linspace(1,5,10)\n",
        "a_t = torch.linspace(1,5,10)\n",
        "print(a_np)\n",
        "print(a_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzI6VkgMhvvX"
      },
      "source": [
        "# Create uniform random numbers from 0 to 1\n",
        "a = torch.rand(5, 3)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbWciFathsmL"
      },
      "source": [
        "# Create gaussion random numbers with mean 0 and std 1\n",
        "a = torch.randn(5, 3)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjqGcmRfhoJF"
      },
      "source": [
        "# Torch Max\n",
        "a = torch.Tensor([[1,0,0],[1,0,0],[0,1,0],[0,0,1]])\n",
        "print(torch.max(a,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjCvcceTicor"
      },
      "source": [
        "# Reshape a torch tensor\n",
        "a = torch.linspace(1,10,10).view(2,5)\n",
        "a = torch.linspace(1,10,10).reshape(2,5)\n",
        "a = torch.linspace(1,10,10).view(-1,2)\n",
        "a = torch.linspace(1,10,10).reshape(-1,2)\n",
        "\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wWf1I4LucDs"
      },
      "source": [
        "# Unsqueeze and squeeze dimensions\n",
        "x = torch.linspace(0, 5, 5)\n",
        "print(x)\n",
        "x = torch.unsqueeze(x, dim=0) \n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdMoDX2g66fi"
      },
      "source": [
        "x = torch.linspace(0, 5, 5)\n",
        "print(x)\n",
        "x = torch.unsqueeze(x, dim=1) \n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8KgXNGtulXJ"
      },
      "source": [
        "# Concatenate\n",
        "x = torch.Tensor([1,2,3])\n",
        "y = torch.cat((x,x,x))\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raZtHK1aupRa"
      },
      "source": [
        "# Transpose\n",
        "x = torch.Tensor([[1,2],[3,4]])\n",
        "y = torch.t(x)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdb3LbkP5_Ut"
      },
      "source": [
        "# Activity: Tensor Operations\n",
        "\n",
        "x = torch.Tensor([1,1])\n",
        "x = torch.unsqueeze(x,dim=0)\n",
        "#print(x)\n",
        "w = torch.Tensor([[1,2],[3,4]])\n",
        "#print(w)\n",
        "b = torch.Tensor([[2],[2]])\n",
        "b = torch.t(b)\n",
        "#print(b)\n",
        "y = torch.mm(b,w)+x\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTniAZQFh3gK"
      },
      "source": [
        "# Appendix: Numpy Tutorial\n",
        "# Matrix Multiplication\n",
        "\n",
        "a = np.array([[1,1],[2,2]])\n",
        "b = np.array([3,3])\n",
        "print(np.matmul(b,a))\n",
        "print(np.matmul(a,b))\n",
        "print(a.dot(b))\n",
        "print(a.T.dot(b))\n",
        "print(b*a)\n",
        "print(a*b)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyzQPio8ur_r"
      },
      "source": [
        "# Appendix: Numpy Tutorial\n",
        "# Expand and Squeeze\n",
        "\n",
        "a = np.array([1,3])\n",
        "print(a.shape)\n",
        "b = np.expand_dims(a,axis=0)\n",
        "b = np.expand_dims(a,axis=1)\n",
        "b = a[np.newaxis]\n",
        "print(b.shape)\n",
        "c = np.squeeze(b)\n",
        "print(c.shape)\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbNhSJ6_zc4k"
      },
      "source": [
        "# Gradient and Back Propagation\n",
        "x = torch.Tensor([5])\n",
        "x.requires_grad=True\n",
        "y = x*x\n",
        "y.backward()\n",
        "print('x gradient = ', x.grad.numpy())\n",
        "print('x gradient = ', x.grad.detach().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2zQAtwA0dHu"
      },
      "source": [
        "# Gradient\n",
        "x = torch.Tensor([-2])\n",
        "x.requires_grad=True\n",
        "y = torch.Tensor([5])\n",
        "y.requires_grad=True\n",
        "z = torch.Tensor([-4])\n",
        "z.requires_grad=True\n",
        "f = (x+y)*z    \n",
        "\n",
        "f.backward()\n",
        "print('x gradient = ',x.grad.numpy())    \n",
        "print('y gradient = ',y.grad.numpy())     \n",
        "print('z gradient = ',z.grad.numpy())   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x39nM7ndCrr"
      },
      "source": [
        "# Activity: Gradient\n",
        "x = torch.Tensor([2])\n",
        "x.requires_grad=True\n",
        "w = torch.Tensor([3])\n",
        "w.requires_grad=True\n",
        "b = torch.Tensor([4])\n",
        "b.requires_grad=True\n",
        "y = w * x + b    \n",
        "\n",
        "# Compute gradients\n",
        "y.backward()\n",
        "\n",
        "# Print out the gradients.\n",
        "print('x gradient = ', x.grad.numpy())     \n",
        "print('w gradient = ', w.grad.numpy())    \n",
        "print('b gradient = ', b.grad.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJadEh2k3rhT"
      },
      "source": [
        "# Activity: Gradient\n",
        "x = torch.Tensor([2])\n",
        "x.requires_grad=True\n",
        "y = x**2+5*x+2 \n",
        "y.backward()\n",
        "print('x gradient = ', x.grad.numpy())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPXRZX6ibWPJ"
      },
      "source": [
        "# Topic 2 Neural Network for Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyAhWaDWMn8H"
      },
      "source": [
        "## Activation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFFQYaYJMj2P"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "x = torch.linspace(-10,10,100)\n",
        "x_np = x.numpy()\n",
        "\n",
        "# Relu Activation Function\n",
        "x_relu = F.relu(x).data.numpy()\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(x_np,x_relu)\n",
        "plt.title('relu')\n",
        "\n",
        "# Sigmoid Activation Function\n",
        "x_sigmoid = F.sigmoid(x).data.numpy()\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(x_np,x_sigmoid)\n",
        "plt.title('sigmoid')\n",
        "\n",
        "# Softplus Activation Function\n",
        "x_softplus = F.softplus(x).data.numpy()\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(x_np,x_softplus)\n",
        "plt.title('softplus')\n",
        "\n",
        "# Hyperbolic Tanh Activation Function\n",
        "x_tanh = F.tanh(x).data.numpy()\n",
        "plt.subplot(2,2,4)\n",
        "plt.plot(x_np,x_tanh)\n",
        "plt.title('tanh')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1qhtFgjH0ml"
      },
      "source": [
        "## Simple Linear Regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfjbDEBnb5nH"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dbXJLdAb-Sn"
      },
      "source": [
        "# Hyper parameters\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Step 1: Setup\n",
        "X_train = [1,2,3,4,5]\n",
        "y_train = [0,-1.1,-1.8,-3.1,-4.5]\n",
        "\n",
        "X = torch.Tensor(X_train)\n",
        "y = torch.Tensor(y_train)\n",
        "\n",
        "W = torch.rand(1)\n",
        "b = torch.rand(1)\n",
        "\n",
        "W.requires_grad=True\n",
        "b.requires_grad=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO_9eX4gdQjB"
      },
      "source": [
        "# Step 2: Optimizer\n",
        "optimizer = torch.optim.SGD([W,b], lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q44h-938dTSq"
      },
      "source": [
        "# Step 3: Train the Model\n",
        "for i in range(1000):\n",
        "\n",
        "\t# Model\n",
        "    yhat = X*W + b\n",
        "\n",
        "    # Loss Function\n",
        "    loss = (yhat - y).pow(2).sum()\n",
        "    \n",
        "    # Compute gradients and update parameters\n",
        "    optimizer.zero_grad()   \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i%50==0: print('step',i,'loss = {:0.2f}'.format(loss.detach().numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y2wvsDcNSif"
      },
      "source": [
        "# Step 4: Evaluate the Model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "W_ = W.detach().numpy()\n",
        "b_ = b.detach().numpy()\n",
        "plt.plot(X_train,y_train,'o')\n",
        "plt.plot(X_train,W_*X_train+b_,'r')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wwjxm4gH_Bf"
      },
      "source": [
        "## Neural Network Predictive Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LXn1ZVJIn_k"
      },
      "source": [
        "### Step 1 Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns18cp-nepZ7"
      },
      "source": [
        "import pandas as pd\n",
        "dataset_path = \"https://raw.githubusercontent.com/tertiarycourses/datasets/master/boston.csv\"                     \n",
        "dataset = pd.read_csv(dataset_path)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZRgXF8U5V-x"
      },
      "source": [
        "dataset = dataset.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as-f5S9I5YN7"
      },
      "source": [
        "x_train = dataset.sample(frac=0.7,random_state=0)\n",
        "x_test = dataset.drop(x_train.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9De5i0275Zzt"
      },
      "source": [
        "y_train = x_train.pop('medv')\n",
        "y_test = x_test.pop('medv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uO1NVtF5bOH"
      },
      "source": [
        "x_train = (x_train - x_train.mean())/(x_train.max()-x_train.min())\n",
        "x_test = (x_test - x_test.mean())/(x_test.max()-x_test.min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrMx0mbe6wu5"
      },
      "source": [
        "import torch\n",
        "x_train = torch.from_numpy(x_train.values).float()\n",
        "y_train = torch.from_numpy(y_train.values).float()\n",
        "\n",
        "x_test = torch.from_numpy(x_test.values).float()\n",
        "y_test = torch.from_numpy(y_test.values).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImdIPcDcGFAr"
      },
      "source": [
        "y_train = torch.unsqueeze(y_train, dim=1) \n",
        "y_test = torch.unsqueeze(y_test, dim=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yPMcsa5-HCs"
      },
      "source": [
        "x_train.shape, y_train.shape,x_test.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So5PZ3YhIwzL"
      },
      "source": [
        "### Step 2 Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItjYrsuu5dGc"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 32\n",
        "L2 = 64\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(13,L1)     \n",
        "        self.fc2 = nn.Linear(L1,L2)\n",
        "        self.fc3 = nn.Linear(L2,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = self.fc3(x)             \n",
        "        return x\n",
        "\n",
        "model = Model() \n",
        "print(model) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9wclFVOI01a"
      },
      "source": [
        "### Step 3 Define the Loss Function and Optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3U04ACC6GNB"
      },
      "source": [
        "#  Loss function\n",
        "\n",
        "loss_func = nn.MSELoss()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OilVgBn66G9F"
      },
      "source": [
        "# Optimizer\n",
        "\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBw7dlX6JPVG"
      },
      "source": [
        "### Step 4 Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09vfhfgp6aI8"
      },
      "source": [
        "for i in range(1000):\n",
        "\n",
        "\t# Model prediction\n",
        "    yhat = model(x_train)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = loss_func(yhat, y_train)\n",
        "    #loss = F.mse_loss(yhat,y)\n",
        "\n",
        "    # Compute gradients and update parameters     \n",
        "    optimizer.zero_grad()   \n",
        "    loss.backward()         \n",
        "    optimizer.step()       \n",
        "\n",
        "    if i%50==0: print('step',i,'loss = {:0.2f}'.format(loss.detach().numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjw3w75aLzN9"
      },
      "source": [
        "### Step 5 Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEJZB0zH6l8_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_hat = model(x_test)\n",
        "\n",
        "plt.scatter(y_test.data.numpy(), y_hat.data.numpy())\n",
        "plt.xlabel('True Values [Housing Price]')\n",
        "plt.ylabel('Predictions [Housing Price]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "plt.plot([0, 100], [0, 100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw3KpSEGA7Ty"
      },
      "source": [
        "y_hat.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XYniWyCOpji"
      },
      "source": [
        "## Save and Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkn0gAOtFiL1"
      },
      "source": [
        "torch.save(model,'./regression.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjuqTi1JNa7F"
      },
      "source": [
        "new_model=torch.load('./regression.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9OdIbhTOTcE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_hat = new_model(x_test)\n",
        "\n",
        "plt.scatter(y_test.data.numpy(), y_hat.data.numpy())\n",
        "plt.xlabel('True Values [Housing Price]')\n",
        "plt.ylabel('Predictions [Housing Price]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "plt.plot([0, 100], [0, 100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvelV5hrO2kI"
      },
      "source": [
        "## Activity: Predictive Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04GMNiP-P5jD"
      },
      "source": [
        "### Step 1 Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGjfmx_YOW50"
      },
      "source": [
        "import pandas as pd\n",
        "dataset_path = \"https://raw.githubusercontent.com/tertiarycourses/datasets/master/iris.csv\"\n",
        "                     \n",
        "dataset = pd.read_csv(dataset_path)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD3hZcxpO7zp"
      },
      "source": [
        "dataset = dataset.dropna()\n",
        "dataset.pop('species')\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHkS-SueO8Jl"
      },
      "source": [
        "x_train = dataset.sample(frac=0.7,random_state=0)\n",
        "x_test = dataset.drop(x_train.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUPBVmV5O_9c"
      },
      "source": [
        "y_train = x_train.pop('sepal_width')\n",
        "y_test = x_test.pop('sepal_width')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCqBnnnpPHx0"
      },
      "source": [
        "x_train = (x_train - x_train.mean())/(x_train.max()-x_train.min())\n",
        "x_test = (x_test - x_test.mean())/(x_test.max()-x_test.min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGi64hZEPJqI"
      },
      "source": [
        "x_train = torch.from_numpy(x_train.values).float()\n",
        "y_train = torch.from_numpy(y_train.values).float()\n",
        "\n",
        "x_test = torch.from_numpy(x_test.values).float()\n",
        "y_test = torch.from_numpy(y_test.values).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey0ZAW46PRN6"
      },
      "source": [
        "y_train = torch.unsqueeze(y_train, dim=1) \n",
        "y_test = torch.unsqueeze(y_test, dim=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtU9lexgPTCG"
      },
      "source": [
        "x_train.shape, y_train.shape,x_test.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wNP54DhQF0_"
      },
      "source": [
        "### Step 2 Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L2u3hPLPVEa"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 32\n",
        "L2 = 64\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(3,L1)     \n",
        "        self.fc2 = nn.Linear(L1,L2)\n",
        "        self.fc3 = nn.Linear(L2,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = self.fc3(x)             \n",
        "        return x\n",
        "\n",
        "model = Model() \n",
        "print(model) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhE7L8cvQPz2"
      },
      "source": [
        "### Step 3 Define the Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKRPul_HPZ6x"
      },
      "source": [
        "#  Loss function\n",
        "\n",
        "loss_func = nn.MSELoss()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIPapFsePen0"
      },
      "source": [
        "# Optimizer\n",
        "\n",
        "learning_rate = 0.0001\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZJ4DgwtQUhK"
      },
      "source": [
        "### Step 4 Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsR_ml9SPhKZ"
      },
      "source": [
        "for i in range(1000):\n",
        "\n",
        "\t# Model prediction\n",
        "    yhat = model(x_train)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = loss_func(yhat, y_train)\n",
        "    #loss = F.mse_loss(yhat,y)\n",
        "\n",
        "    # Compute gradients and update parameters     \n",
        "    optimizer.zero_grad()   \n",
        "    loss.backward()         \n",
        "    optimizer.step()       \n",
        "\n",
        "    if i%50==0: print('step',i,'loss = {:0.2f}'.format(loss.detach().numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIpnqun-Qhcw"
      },
      "source": [
        "### Step 5 Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQRpr1_0Pjhj"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_hat = model(x_test)\n",
        "\n",
        "plt.scatter(y_test.data.numpy(), y_hat.data.numpy())\n",
        "plt.xlabel('True Values Sepal Width')\n",
        "plt.ylabel('Predictions Sepal Width')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "plt.plot([0, 100], [0, 100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xVeTe7aRx89"
      },
      "source": [
        "# Topic 3 Neural Network for Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cTyqPnmcBzS"
      },
      "source": [
        "## MNIST Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f9dWS4jiwLT"
      },
      "source": [
        "### Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHeyy3IoSZPZ"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,), (0.5,))\n",
        "     ])\n",
        "\n",
        "# Hyper Parameters             \n",
        "BATCH_SIZE = 200\n",
        "LR = 0.001 \n",
        "EPOCH = 10\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./mnist', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./mnist', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FLCSN0d5D-x"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image,label = next(iter(trainloader))\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.imshow(image[i][0], cmap='gray')\n",
        "  plt.title(\"Ground Truth: {}\".format(label[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9NXzwwdi3Lb"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWdKLPJWYRpF"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 32\n",
        "L2 = 64\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784,L1)     \n",
        "        self.fc2 = nn.Linear(L1,L2)\n",
        "        self.fc3 = nn.Linear(L2,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = self.fc3(x)   \n",
        "        return x\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Model() \n",
        "model = model.to(device)\n",
        "print(model) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_zYqeegi-i6"
      },
      "source": [
        "### Define the Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5yE7i5cYRwD"
      },
      "source": [
        "# Loss Function\n",
        "loss_func = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb7yPy8ui_7y"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db2mKFxXY4s-"
      },
      "source": [
        "train_loss = []\n",
        "train_acc = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "def validation():\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for (x,y) in testloader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            x = x.reshape(-1,28*28)\n",
        "\n",
        "            yhat = model(x)\n",
        "            loss = loss_func(yhat, y)  \n",
        "\n",
        "            _, y_pred = torch.max(yhat.data, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (y_pred == y.data).sum()\n",
        "            acc = correct.double()/total\n",
        "            loss = loss.cpu().detach().numpy()\n",
        "        return acc,loss\n",
        "\n",
        "for epoch in range(EPOCH): \n",
        "\n",
        "    print('Epoch {}/{}'.format(epoch, EPOCH - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    total = 0   \n",
        "    correct = 0 \n",
        "\n",
        "    for i, (x, y) in enumerate(trainloader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        x = x.reshape(-1,28*28)\n",
        "\n",
        "        yhat = model(x)\n",
        "        loss = loss_func(yhat, y)  \n",
        "\n",
        "        optimizer.zero_grad()            \n",
        "        loss.backward()                  \n",
        "        optimizer.step()         \n",
        "      \n",
        "\n",
        "        _, y_pred = torch.max(yhat.data, 1)\n",
        "        total += y.size(0)\n",
        "        correct += (y_pred == y.data).sum()\n",
        "\n",
        "    _acc = correct.double()/total\n",
        "    _loss = loss.cpu().detach().numpy()\n",
        "    train_loss.append(_loss)\n",
        "    train_acc.append(_acc)\n",
        "            \n",
        "    _val_acc,_val_loss = validation()\n",
        "    val_loss.append(_val_loss)\n",
        "    val_acc.append(_val_acc)\n",
        "\n",
        "    print('loss: {:.4f} acc: {:.4f} val_loss: {:.4f} val_acc: {:.4f} '.format(_loss,_acc,_val_loss,_val_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYWNEQzzjDdx"
      },
      "source": [
        "### Step 5 Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tafi1E0X8H5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch = range(len(train_loss))\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,train_loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,train_acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN1wlpgxhOGf"
      },
      "source": [
        "_val_acc,_val_loss = validation()\n",
        "\n",
        "print('Test accuracy: {:.4f}'.format(_val_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plumZ8NLX2Nd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7wv4vI5eZjO"
      },
      "source": [
        "## Activity: Fashion MNIST Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n5DkX1IIDOV"
      },
      "source": [
        "### Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWqDZIRWedpx"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,), (0.5,))\n",
        "     ])\n",
        "\n",
        "# Hyper Parameters             \n",
        "BATCH_SIZE = 100\n",
        "LR = 0.001 \n",
        "EPOCH = 10\n",
        "\n",
        "trainset = torchvision.datasets.FashionMNIST(root='./fashion_mnist', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.FashionMNIST(root='./fashion_mnist', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD736TNIIAkx"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgjTa0Qserd_"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 32\n",
        "L2 = 64\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784,L1)     \n",
        "        self.fc2 = nn.Linear(L1,L2)\n",
        "        self.fc3 = nn.Linear(L2,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = self.fc3(x)       \n",
        "        return x\n",
        "\n",
        "model = Model() \n",
        "model = model.to(device)\n",
        "print(model) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UGAZ04LIGaM"
      },
      "source": [
        "### Define the loss function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlUfPP3Ee3ee"
      },
      "source": [
        "# Loss Function\n",
        "loss_func = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F4s6VqdaGmT"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "306NmZEaUbIu"
      },
      "source": [
        "train_loss = []\n",
        "train_acc = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "def validation():\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for (x,y) in testloader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            x = x.reshape(-1,28*28)\n",
        "\n",
        "            yhat = model(x)\n",
        "            loss = loss_func(yhat, y)  \n",
        "\n",
        "            _, y_pred = torch.max(yhat.data, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (y_pred == y.data).sum()\n",
        "            acc = correct.double()/total\n",
        "            loss = loss.cpu().detach().numpy()\n",
        "        return acc,loss\n",
        "\n",
        "for epoch in range(EPOCH): \n",
        "\n",
        "    print('Epoch {}/{}'.format(epoch, EPOCH - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    total = 0   \n",
        "    correct = 0 \n",
        "\n",
        "    for i, (x, y) in enumerate(trainloader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        x = x.reshape(-1,28*28)\n",
        "\n",
        "        yhat = model(x)\n",
        "        loss = loss_func(yhat, y)  \n",
        "\n",
        "        optimizer.zero_grad()            \n",
        "        loss.backward()                  \n",
        "        optimizer.step()         \n",
        "      \n",
        "\n",
        "        _, y_pred = torch.max(yhat.data, 1)\n",
        "        total += y.size(0)\n",
        "        correct += (y_pred == y.data).sum()\n",
        "\n",
        "    _acc = correct.double()/total\n",
        "    _loss = loss.cpu().detach().numpy()\n",
        "    train_loss.append(_loss)\n",
        "    train_acc.append(_acc)\n",
        "            \n",
        "    _val_acc,_val_loss = validation()\n",
        "    val_loss.append(_val_loss)\n",
        "    val_acc.append(_val_acc)\n",
        "\n",
        "    print('loss: {:.4f} acc: {:.4f} val_loss: {:.4f} val_acc: {:.4f} '.format(_loss,_acc,_val_loss,_val_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j3uo7mRHyBU"
      },
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HGNdB4pdE9R"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch = range(len(train_loss))\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,train_loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,train_acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N4PAR54fASi"
      },
      "source": [
        "_val_acc,_val_loss = validation()\n",
        "\n",
        "print('Test accuracy: {:.4f}'.format(_val_acc))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kze0f3VXjIFa"
      },
      "source": [
        "# Topic 4 Convolutional Neural Network for Pattern Recognition\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfVmcqnUdW43"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cezdjeMTu45G"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,), (0.5,))\n",
        "     ])\n",
        "\n",
        "# Hyper Parameters             \n",
        "BATCH_SIZE = 200\n",
        "LR = 0.001 \n",
        "EPOCH = 10\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./mnist', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True,num_workers=4)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./mnist', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False,num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzufVUondZt4"
      },
      "source": [
        "## Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaur5V-uTpQc"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1,16,3,1,1)\n",
        "        self.conv2 = nn.Conv2d(16,32,3,1,1)\n",
        "        self.fc1 = nn.Linear(32*7*7,128)\n",
        "        self.fc2 = nn.Linear(128, 10)     \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view( x.size(0),-1) \n",
        "        x = F.relu(self.fc1(x))              \n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = Model()\n",
        "model = model.to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LMjouRZdb_o"
      },
      "source": [
        "## Define Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8lKoivsVE2a"
      },
      "source": [
        "# Loss Function\n",
        "loss_func = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB-1pch4dehW"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9yMLMhJUqms"
      },
      "source": [
        "train_loss = []\n",
        "train_acc = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "def validation():\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for (x,y) in testloader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            yhat = model(x)\n",
        "            loss = loss_func(yhat, y)  \n",
        "\n",
        "            _, y_pred = torch.max(yhat.data, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (y_pred == y.data).sum()\n",
        "            acc = correct.double()/total\n",
        "            loss = loss.cpu().detach().numpy()\n",
        "        return acc,loss\n",
        "\n",
        "for epoch in range(EPOCH): \n",
        "\n",
        "    print('Epoch {}/{}'.format(epoch, EPOCH - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    total = 0   \n",
        "    correct = 0 \n",
        "\n",
        "    for i, (x, y) in enumerate(trainloader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        yhat = model(x)\n",
        "        loss = loss_func(yhat, y)  \n",
        "\n",
        "        optimizer.zero_grad()            \n",
        "        loss.backward()                  \n",
        "        optimizer.step()         \n",
        "      \n",
        "\n",
        "        _, y_pred = torch.max(yhat.data, 1)\n",
        "        total += y.size(0)\n",
        "        correct += (y_pred == y.data).sum()\n",
        "\n",
        "    _acc = correct.double()/total\n",
        "    _loss = loss.cpu().detach().numpy()\n",
        "    train_loss.append(_loss)\n",
        "    train_acc.append(_acc)\n",
        "            \n",
        "    _val_acc,_val_loss = validation()\n",
        "    val_loss.append(_val_loss)\n",
        "    val_acc.append(_val_acc)\n",
        "\n",
        "    print('loss: {:.4f} acc: {:.4f} val_loss: {:.4f} val_acc: {:.4f} '.format(_loss,_acc,_val_loss,_val_acc))\n",
        "           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxGU64eydj2E"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6f0sEAbLw6B"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch = range(len(train_loss))\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,train_loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,train_acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9jqqRiqy34I"
      },
      "source": [
        "_val_acc,_val_loss = validation()\n",
        "\n",
        "print('Test accuracy: {:.4f}'.format(_val_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RIGyBLzdtGt"
      },
      "source": [
        "## Activity: CNN on CIFAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koAag2qVd3S6"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "     ])\n",
        "\n",
        "#Hyper Parameters\n",
        "BATCH_SIZE = 200\n",
        "LR = 0.001 \n",
        "EPOCH = 10\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./cifar10', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNUZsHqOd60G"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3,16,3,1,1)\n",
        "        self.conv2 = nn.Conv2d(16,32,3,1,1)\n",
        "        self.fc1 = nn.Linear(32*8*8,128)\n",
        "        self.fc2 = nn.Linear(128, 10)     \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view( x.size(0),-1) \n",
        "        x = F.relu(self.fc1(x))              \n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = Model()\n",
        "model = model.to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcQiiffzd_WG"
      },
      "source": [
        "# Loss Function\n",
        "loss_func = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbJoRh0ueKHo"
      },
      "source": [
        "train_loss = []\n",
        "train_acc = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "def validation():\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for (x,y) in testloader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            yhat = model(x)\n",
        "            loss = loss_func(yhat, y)  \n",
        "\n",
        "            _, y_pred = torch.max(yhat.data, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (y_pred == y.data).sum()\n",
        "            acc = correct.double()/total\n",
        "            loss = loss.cpu().detach().numpy()\n",
        "        return acc,loss\n",
        "\n",
        "for epoch in range(EPOCH): \n",
        "\n",
        "    print('Epoch {}/{}'.format(epoch, EPOCH - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    total = 0   \n",
        "    correct = 0 \n",
        "\n",
        "    for i, (x, y) in enumerate(trainloader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        yhat = model(x)\n",
        "        loss = loss_func(yhat, y)  \n",
        "\n",
        "        optimizer.zero_grad()            \n",
        "        loss.backward()                  \n",
        "        optimizer.step()         \n",
        "      \n",
        "\n",
        "        _, y_pred = torch.max(yhat.data, 1)\n",
        "        total += y.size(0)\n",
        "        correct += (y_pred == y.data).sum()\n",
        "\n",
        "    _acc = correct.double()/total\n",
        "    _loss = loss.cpu().detach().numpy()\n",
        "    train_loss.append(_loss)\n",
        "    train_acc.append(_acc)\n",
        "            \n",
        "    _val_acc,_val_loss = validation()\n",
        "    val_loss.append(_val_loss)\n",
        "    val_acc.append(_val_acc)\n",
        "\n",
        "    print('loss: {:.4f} acc: {:.4f} val_loss: {:.4f} val_acc: {:.4f} '.format(_loss,_acc,_val_loss,_val_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-Qq3sQdeNpS"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch = range(len(train_loss))\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,train_loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,train_acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xDZ2YFzexLR"
      },
      "source": [
        "_val_acc,_val_loss = validation()\n",
        "\n",
        "print('Test accuracy: {:.4f}'.format(_val_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDXsP9SSFaNg"
      },
      "source": [
        "## Pytorch Tutorial on CIRAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEaCXcMRNa46"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WvLIBW_FJkY"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhEXHqeji6e8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uknoRjo9FlVC"
      },
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyFFB_AHZjmY"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwtpflyWbXDL"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZmKO7XTbZwY"
      },
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHgnM3thboo0"
      },
      "source": [
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxuvvFSpbqza"
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM0hH-jellE5"
      },
      "source": [
        "# Topic 5 Data Visualization with Tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv3OvQQp-fRm"
      },
      "source": [
        "## Fashion MNIST Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B9SPGr--j06"
      },
      "source": [
        "### Run the Fashion MNIST model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMsTxlA0xcvv"
      },
      "source": [
        "# imports\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# transforms\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# datasets\n",
        "trainset = torchvision.datasets.FashionMNIST('./data',\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=transform)\n",
        "testset = torchvision.datasets.FashionMNIST('./data',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=transform)\n",
        "\n",
        "# dataloaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                        shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                        shuffle=False, num_workers=2)\n",
        "\n",
        "# constant for classes\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
        "\n",
        "# helper function to show an image\n",
        "# (used in the `plot_classes_preds` function below)\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKfGHHTryODV"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCYYh97Kyes7"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQaGqC0t-sUw"
      },
      "source": [
        "### Setup Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlhIVi77ylUe"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAi7GBGyyo4t"
      },
      "source": [
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=True)\n",
        "\n",
        "# write to tensorboard\n",
        "writer.add_image('four_fashion_mnist_images', img_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bzmgZlU-wBQ"
      },
      "source": [
        "### Show the data on Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWg0w_Tpz2Q3"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrrhlzS-yr5S"
      },
      "source": [
        "%tensorboard --logdir=runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcOVs7di-yZA"
      },
      "source": [
        "### Show Model Architecture on Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ITltxsD0mIQ"
      },
      "source": [
        "writer.add_graph(net, images)\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXt2CqRl0q03"
      },
      "source": [
        "%tensorboard --logdir=runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e3RtNBy035O"
      },
      "source": [
        "# helper functions\n",
        "\n",
        "def images_to_probs(net, images):\n",
        "    '''\n",
        "    Generates predictions and corresponding probabilities from a trained\n",
        "    network and a list of images\n",
        "    '''\n",
        "    output = net(images)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, preds_tensor = torch.max(output, 1)\n",
        "    preds = np.squeeze(preds_tensor.numpy())\n",
        "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
        "\n",
        "\n",
        "def plot_classes_preds(net, images, labels):\n",
        "    '''\n",
        "    Generates matplotlib Figure using a trained network, along with images\n",
        "    and labels from a batch, that shows the network's top prediction along\n",
        "    with its probability, alongside the actual label, coloring this\n",
        "    information based on whether the prediction was correct or not.\n",
        "    Uses the \"images_to_probs\" function.\n",
        "    '''\n",
        "    preds, probs = images_to_probs(net, images)\n",
        "    # plot the images in the batch, along with predicted and true labels\n",
        "    fig = plt.figure(figsize=(12, 48))\n",
        "    for idx in np.arange(4):\n",
        "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
        "        matplotlib_imshow(images[idx], one_channel=True)\n",
        "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
        "            classes[preds[idx]],\n",
        "            probs[idx] * 100.0,\n",
        "            classes[labels[idx]]),\n",
        "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
        "    return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx9gGjOP-_aX"
      },
      "source": [
        "### Show the Training Loss on Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_3dWAnk1HDH"
      },
      "source": [
        "running_loss = 0.0\n",
        "for epoch in range(1):  # loop over the dataset multiple times\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
        "\n",
        "            # ...log the running loss\n",
        "            writer.add_scalar('training loss',\n",
        "                            running_loss / 1000,\n",
        "                            epoch * len(trainloader) + i)\n",
        "\n",
        "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
        "            # random mini-batch\n",
        "            writer.add_figure('predictions vs. actuals',\n",
        "                            plot_classes_preds(net, inputs, labels),\n",
        "                            global_step=epoch * len(trainloader) + i)\n",
        "            running_loss = 0.0\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMYBEqSj1MsD"
      },
      "source": [
        "%tensorboard --logdir=runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VLekHmv_DRg"
      },
      "source": [
        "### Show the Precison Recall Curves on Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccdJU0IF2Awm"
      },
      "source": [
        "# takes ~10 seconds to run\n",
        "class_probs = []\n",
        "class_preds = []\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        output = net(images)\n",
        "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
        "        _, class_preds_batch = torch.max(output, 1)\n",
        "\n",
        "        class_probs.append(class_probs_batch)\n",
        "        class_preds.append(class_preds_batch)\n",
        "\n",
        "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
        "test_preds = torch.cat(class_preds)\n",
        "\n",
        "# helper function\n",
        "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
        "    '''\n",
        "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
        "    precision-recall curve\n",
        "    '''\n",
        "    tensorboard_preds = test_preds == class_index\n",
        "    tensorboard_probs = test_probs[:, class_index]\n",
        "\n",
        "    writer.add_pr_curve(classes[class_index],\n",
        "                        tensorboard_preds,\n",
        "                        tensorboard_probs,\n",
        "                        global_step=global_step)\n",
        "    writer.close()\n",
        "\n",
        "# plot all the pr curves\n",
        "for i in range(len(classes)):\n",
        "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpnZsAq82FVV"
      },
      "source": [
        "%tensorboard --logdir=runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbj-4Z9O-YgI"
      },
      "source": [
        "## Activity: MNIST on Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvrIKzG47w0s"
      },
      "source": [
        "# imports\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# transforms\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# datasets\n",
        "trainset = torchvision.datasets.MNIST('./data',\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=transform)\n",
        "testset = torchvision.datasets.MNIST('./data',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=transform)\n",
        "\n",
        "# dataloaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                        shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                        shuffle=False, num_workers=2)\n",
        "\n",
        "# constant for classes\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
        "\n",
        "# helper function to show an image\n",
        "# (used in the `plot_classes_preds` function below)\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHK6XBhT73bZ"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyml6Lf97_kC"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pBO2wWz8EiM"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs2/mnist_experiment_1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4FVup508Juy"
      },
      "source": [
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=True)\n",
        "\n",
        "# write to tensorboard\n",
        "writer.add_image('runs2/four_mnist_images', img_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONoMV2nU8c1y"
      },
      "source": [
        "%tensorboard --logdir=runs2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irehHn6L82vF"
      },
      "source": [
        "running_loss = 0.0\n",
        "for epoch in range(1):  # loop over the dataset multiple times\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
        "\n",
        "            # ...log the running loss\n",
        "            writer.add_scalar('runs2/training loss',\n",
        "                            running_loss / 1000,\n",
        "                            epoch * len(trainloader) + i)\n",
        "\n",
        "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
        "            # random mini-batch\n",
        "            writer.add_figure('predictions vs. actuals',\n",
        "                            plot_classes_preds(net, inputs, labels),\n",
        "                            global_step=epoch * len(trainloader) + i)\n",
        "            running_loss = 0.0\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeccwkIP9q-j"
      },
      "source": [
        "%tensorboard --logdir=runs2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoEQWUrtm7VJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}