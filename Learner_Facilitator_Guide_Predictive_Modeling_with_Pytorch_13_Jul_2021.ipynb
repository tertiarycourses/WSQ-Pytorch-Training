{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Learner/Facilitator Guide - Predictive Modeling with Pytorch  - 13 Jul 2021",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "OBmwaDOqvU_-",
        "ZPXRZX6ibWPJ",
        "XyAhWaDWMn8H",
        "dtA2qbcygh6i",
        "1LXn1ZVJIn_k",
        "So5PZ3YhIwzL",
        "Q9wclFVOI01a",
        "mBw7dlX6JPVG",
        "Sjw3w75aLzN9",
        "9XYniWyCOpji",
        "SvelV5hrO2kI",
        "04GMNiP-P5jD",
        "2wNP54DhQF0_",
        "WhE7L8cvQPz2",
        "1ZJ4DgwtQUhK",
        "rIpnqun-Qhcw",
        "6xVeTe7aRx89",
        "S7wv4vI5eZjO",
        "1n5DkX1IIDOV",
        "FD736TNIIAkx",
        "4UGAZ04LIGaM",
        "5F4s6VqdaGmT",
        "3j3uo7mRHyBU",
        "Kze0f3VXjIFa",
        "KfVmcqnUdW43",
        "TzufVUondZt4",
        "3rLINxWGbzTy"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBmwaDOqvU_-"
      },
      "source": [
        "# Topic 1 Overview of Deep Learning and Pytorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZd_A2zLHqjH"
      },
      "source": [
        "## Install Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2UwZR6jvONy"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovMIm1O4vPky"
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxDOnc69vRTn"
      },
      "source": [
        "print(\"Cuda Current Device: \", torch.cuda.current_device())\n",
        "print(\"Cude Device Count: \", torch.cuda.device_count())\n",
        "print(\"Cude Device Name: \", torch.cuda.get_device_name(0))\n",
        "print(\"Cude Device Available : \", torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTXm_2dZh63x"
      },
      "source": [
        "## Basic Pytorch Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj5zdxGUf6IH"
      },
      "source": [
        "# Create a Torch Vector\n",
        "a = [1, 2, 3]\n",
        "b = torch.Tensor(a)\n",
        "# b = torch.FloatTensor(a)\n",
        "# b = torch.DoubleTensor(a)\n",
        "# b = torch.IntTensor(a)\n",
        "# b = torch.LongTensor(a)\n",
        "print(b)\n",
        "print(b[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUoaYgJMFbIM"
      },
      "source": [
        "a = [1, 2, 3]\n",
        "b = torch.tensor(a)\n",
        "print(b)\n",
        "print(b[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXQCPOCAf-i_"
      },
      "source": [
        "# Create a Torch Matrix\n",
        "a = [[1, 2, 3], [4, 5, 6]]\n",
        "b = torch.tensor(a)\n",
        "print(b)\n",
        "print(b[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XN85oeHgBb6"
      },
      "source": [
        "# Create a 3D Tensor\n",
        "a = [[[1., 2.], [3., 4.]],\n",
        "     [[5., 6.], [7., 8.]]]\n",
        "b = torch.tensor(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yOsyKiSgE3e"
      },
      "source": [
        "# Conversion from Tensor to numpy\n",
        "a = torch.tensor([3])\n",
        "print(a)\n",
        "b = a.numpy()\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jHE-i1znl7H"
      },
      "source": [
        "# Conversion from numpy to Tensor\n",
        "import numpy as np\n",
        "a = np.arange(6).reshape(2,3)\n",
        "print(a)\n",
        "b = torch.from_numpy(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdBf5dyz13yv"
      },
      "source": [
        "# Numpy functions\n",
        "\n",
        "a = [1,2,3,4]\n",
        "b = np.array(a)\n",
        "c = np.sum(b)\n",
        "d = np.mean(b)\n",
        "e = np.max(b)\n",
        "print(c,d,e)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2u2QLZnhXa6"
      },
      "source": [
        "# Torch functions\n",
        "a = [1.,2.,3.,4.]\n",
        "b = torch.tensor(a)\n",
        "c = torch.sum(b)\n",
        "d = torch.mean(b)\n",
        "e = torch.max(b)\n",
        "print(c,d,e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmI9Q9Ghh0my"
      },
      "source": [
        "# Tensor operations\n",
        "a = torch.tensor([1,1])\n",
        "b = torch.tensor([2,2])\n",
        "print(a+b)\n",
        "print(torch.add(a, b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJCTD-SYbDy8"
      },
      "source": [
        "# Tensor operations with GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "a = torch.tensor([1,1]).to(device)\n",
        "b = torch.tensor([2,2]).to(device)\n",
        "c = a+b\n",
        "print(c)\n",
        "print(c.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRYeznRviUw0"
      },
      "source": [
        "# Activity: Tensor Operation with GPU\n",
        "a = torch.tensor([3]).to(device)\n",
        "b = torch.tensor([4]).to(device)\n",
        "c = torch.tensor([5]).to(device)\n",
        "d = a*b+c\n",
        "print(d)\n",
        "print(d.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6332HGEhcqc"
      },
      "source": [
        "# Torch matrix multiplication\n",
        "mat1 = torch.randn(2, 3)\n",
        "mat2 = torch.randn(3, 3)\n",
        "torch.mm(mat1, mat2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbdW_-ZSZtbQ"
      },
      "source": [
        "# Activity: Matrix operation\n",
        "x = torch.tensor([[1,1]])\n",
        "w = torch.tensor([[1,2],[3,4]])\n",
        "b = torch.tensor([[2,2]])\n",
        "print(torch.mm(x,w)+b)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHLAtiyihloR"
      },
      "source": [
        "# Generate Special Torch Tensors\n",
        "a = torch.diag(torch.tensor([1,2,3]))\n",
        "a = torch.eye(3)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsS5foAshq1P"
      },
      "source": [
        "# Torch linspace\n",
        "a = torch.linspace(1,10,10)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzI6VkgMhvvX"
      },
      "source": [
        "# Create uniform random numbers from 0 to 1\n",
        "a = torch.rand(5, 3)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbWciFathsmL"
      },
      "source": [
        "# Create gaussion random numbers with mean 0 and std 1\n",
        "a = torch.randn(5, 3)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjqGcmRfhoJF"
      },
      "source": [
        "# Torch Max\n",
        "a = torch.tensor([[1,0,0],[1,0,0],[0,1,0],[0,0,1]])\n",
        "print(torch.max(a,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLo86xlvK2Ll"
      },
      "source": [
        "# Activity: Torch Max\n",
        "a = torch.tensor([[3,4,-5,2,7,3]])\n",
        "torch.max(a,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjCvcceTicor"
      },
      "source": [
        "# Reshape a torch tensor\n",
        "a = torch.linspace(1,10,10).view(2,5)\n",
        "a = torch.linspace(1,10,10).reshape(2,5)\n",
        "# a = torch.linspace(1,10,10).view(-1,2)\n",
        "# a = torch.linspace(1,10,10).reshape(-1,2)\n",
        "\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wWf1I4LucDs"
      },
      "source": [
        "# Unsqueeze and squeeze dimensions\n",
        "x = torch.linspace(0, 5, 5)\n",
        "print(x)\n",
        "x = torch.unsqueeze(x, dim=0) \n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdMoDX2g66fi"
      },
      "source": [
        "x = torch.linspace(0, 5, 5)\n",
        "print(x)\n",
        "x = torch.unsqueeze(x, dim=1) \n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8KgXNGtulXJ"
      },
      "source": [
        "# Concatenate\n",
        "x = torch.tensor([1,2,3])\n",
        "y = torch.cat((x,x,x))\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raZtHK1aupRa"
      },
      "source": [
        "# Transpose\n",
        "x = torch.tensor([[1,2],[3,4]])\n",
        "y = torch.t(x)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdb3LbkP5_Ut"
      },
      "source": [
        "# Activity: Tensor Operations\n",
        "\n",
        "x = torch.tensor([1,1])\n",
        "x = torch.unsqueeze(x,dim=0)\n",
        "#print(x.shape)\n",
        "w = torch.tensor([[1,2],[3,4]])\n",
        "#print(w.shape)\n",
        "b = torch.tensor([[2],[2]])\n",
        "b = torch.t(b)\n",
        "#print(b.shape)\n",
        "y = torch.mm(x,w)+b\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbNhSJ6_zc4k"
      },
      "source": [
        "# Gradient and Back Propagation\n",
        "x = torch.tensor([5.],requires_grad=True)\n",
        "y = x*x\n",
        "y.backward()\n",
        "\n",
        "x.grad.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J18xNwP9Itkb"
      },
      "source": [
        "x = torch.tensor(1.0, requires_grad = True)\n",
        "y = 2*x**2\n",
        "z = y**3\n",
        "\n",
        "z.backward()\n",
        "\n",
        "x.grad.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2zQAtwA0dHu"
      },
      "source": [
        "# Gradient\n",
        "x = torch.tensor([-2.], requires_grad=True)\n",
        "y = torch.tensor([5.],requires_grad=True)\n",
        "z = torch.tensor([-4.], requires_grad=True)\n",
        "f = (x+y)*z    \n",
        "\n",
        "f.backward()\n",
        "\n",
        "print('x gradient = ',x.grad.item())    \n",
        "print('y gradient = ',y.grad.item())     \n",
        "print('z gradient = ',z.grad.item())    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DXnhDc01YCJ"
      },
      "source": [
        "# Difference between .item and .data\n",
        "a = torch.randn(1)\n",
        "print(a.item())\n",
        "print(a.data)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x39nM7ndCrr"
      },
      "source": [
        "# Activity: Gradient\n",
        "x = torch.tensor([2.], requires_grad=True)\n",
        "w = torch.tensor([3.], requires_grad=True)\n",
        "b = torch.tensor([4.], requires_grad=True)\n",
        "y = w*x + b    \n",
        "\n",
        "# Compute gradients\n",
        "y.backward()\n",
        "\n",
        "# Print out the gradients.\n",
        "print('x gradient = ', x.grad.item())     \n",
        "print('w gradient = ', w.grad.item())    \n",
        "print('b gradient = ', b.grad.item())\n",
        "\n",
        "# Print out the gradients.\n",
        "print('x gradient = ', x.grad)    \n",
        "print('w gradient = ', w.grad)\n",
        "print('b gradient = ', b.grad)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Um9tE0MJkJ5"
      },
      "source": [
        "# Activity: Compute Gradient\n",
        "x = torch.tensor([2.],requires_grad=True)\n",
        "w = torch.tensor([3.],requires_grad=True)\n",
        "b = torch.tensor([4.],requires_grad=True)\n",
        "y = w * x + b    \n",
        "\n",
        "y.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgjT09eoRh5S"
      },
      "source": [
        "# Activity: Compute Gradient\n",
        "\n",
        "x = torch.tensor(1.0, requires_grad = True)\n",
        "y = 2*x**2\n",
        "z = y**3\n",
        "\n",
        "z.backward() #Computes the gradient \n",
        "print(x.grad.item()) #Print dz/dx "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPXRZX6ibWPJ"
      },
      "source": [
        "# Topic 2 Neural Network for Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyAhWaDWMn8H"
      },
      "source": [
        "## Activation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFFQYaYJMj2P"
      },
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "x = torch.linspace(-10,10,100)\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "# Relu Activation Function\n",
        "x_relu = torch.relu(x)\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.plot(x,x_relu)\n",
        "plt.title('relu')\n",
        "\n",
        "# Sigmoid Activation Function\n",
        "x_sigmoid = torch.sigmoid(x)\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(x,x_sigmoid)\n",
        "plt.title('sigmoid')\n",
        "\n",
        "# Hyperbolic Tanh Activation Function\n",
        "x_tanh = torch.tanh(x)\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.plot(x,x_tanh)\n",
        "plt.title('tanh')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1qhtFgjH0ml"
      },
      "source": [
        "## Simple Linear Regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dbXJLdAb-Sn"
      },
      "source": [
        "# Step 1: Setup\n",
        "import torch\n",
        "\n",
        "X = torch.tensor([1.,2.,3,4,5])\n",
        "y = torch.tensor([0,-1.1,-1.8,-3.1,-4.5])\n",
        "\n",
        "W = torch.rand(1,requires_grad=True)\n",
        "b = torch.rand(1,requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO_9eX4gdQjB"
      },
      "source": [
        "# Step 2: Optimizer\n",
        "learning_rate = 0.001\n",
        "\n",
        "optimizer = torch.optim.SGD([W,b], lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q44h-938dTSq"
      },
      "source": [
        "# Step 3: Train the Model\n",
        "\n",
        "for i in range(1000):\n",
        "    # Model\n",
        "    yhat = X*W+b\n",
        "\n",
        "    # Loss Function\n",
        "    loss = (yhat-y).pow(2).sum()\n",
        "\n",
        "    #Compute gradient\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i%50==0: print(f'i:{i}, W:{W.item()}, b:{b.item()}, loss:{loss.item()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSZZUM_SGqWc"
      },
      "source": [
        "# Alternative Method using MSELoss method\n",
        "# Step 3: Train the Model\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "for i in range(1000):\n",
        "    # Model\n",
        "    yhat = X*W+b\n",
        "\n",
        "    # Loss Function\n",
        "    loss = criterion(yhat,y)\n",
        "\n",
        "    #Compute gradient\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i%50==0: print(f'i:{i}, W:{W.item()}, b:{b.item()}, loss:{loss.item()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y2wvsDcNSif"
      },
      "source": [
        "# Step 4: Evaluate the Model\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "W_ = W.item()\n",
        "b_ = b.item()\n",
        "\n",
        "plt.plot(X,y,'o')\n",
        "plt.plot(X,X*W_+b_,'r')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz0EkmLtVTIn"
      },
      "source": [
        "# Explicit Zero Grad Demo\n",
        "# Without using optimizer\n",
        "\n",
        "import torch\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "X = torch.tensor([1.,2.,3,4,5])\n",
        "y = torch.tensor([0,-1.1,-1.8,-3.1,-4.5])\n",
        "\n",
        "W = torch.randn(1, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "\n",
        "for i in range(1000):\n",
        "    yhat = X*W+b\n",
        "\n",
        "    loss = (yhat - y).pow(2).sum()\n",
        "    loss.backward()\n",
        "\n",
        "    W.data -= learning_rate * W.grad.item()\n",
        "    b.data -= learning_rate * b.grad.item()\n",
        "\n",
        "    W.grad.data.zero_()\n",
        "    b.grad.data.zero_()\n",
        "    \n",
        "    if i%50==0: print(f'i:{i}, W:{W.item()}, b:{b.item()}, loss:{loss.item()}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjT2x8mSVlA6"
      },
      "source": [
        "# Step 4: Evaluate the Model\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "W_ = W.item()\n",
        "b_ = b.item()\n",
        "\n",
        "plt.plot(X,y,'o')\n",
        "plt.plot(X,X*W_+b_,'r')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wwjxm4gH_Bf"
      },
      "source": [
        "## Neural Network Predictive Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUzOMUqcf-Gx"
      },
      "source": [
        "# Step 1: Setup\n",
        "import torch\n",
        "\n",
        "X = torch.tensor([1.,2.,3,4,5])\n",
        "y = torch.tensor([0,-1.1,-1.8,-3.1,-4.5])\n",
        "\n",
        "X = torch.unsqueeze(X, dim=1) \n",
        "y = torch.unsqueeze(y, dim=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1whjKKHngXbV"
      },
      "source": [
        "# Step 2: Define Model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 3\n",
        "L2 = 5\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.fc1 = nn.Linear(1,L1)     \n",
        "        self.fc2 = nn.Linear(L1,L2)\n",
        "        self.fc3 = nn.Linear(L2,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = self.fc3(x)             \n",
        "        return x\n",
        "\n",
        "model = Model() \n",
        "print(model) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmexZ2HzkK_l"
      },
      "source": [
        "# Alternative way to define the model\n",
        "# Step 2: Define Model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 3\n",
        "L2 = 5\n",
        "\n",
        "model = nn.Sequential(nn.Linear(1, L1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(L1, L2),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(L2, 1))\n",
        "print(model) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxjYOc2ZgbXO"
      },
      "source": [
        "# Step 3: Select Optimizer\n",
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAz-OYUlgd0x"
      },
      "source": [
        "# Step 4: Training\n",
        "\n",
        "for i in range(1000):\n",
        "\n",
        "\t# Model prediction\n",
        "    yhat = model(X)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = (yhat - y).pow(2).sum()\n",
        "\n",
        "    # Compute gradients and update parameters     \n",
        "    optimizer.zero_grad()   \n",
        "    loss.backward()         \n",
        "    optimizer.step()       \n",
        "\n",
        "    if i%50==0: print(f'i:{i}, W:{W.item()}, b:{b.item()}, loss:{loss.item()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpBjV6GiggV8"
      },
      "source": [
        "# Step 5: Evaluate the Model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(X,y,'o')\n",
        "plt.plot(X,model(X).data,'r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtA2qbcygh6i"
      },
      "source": [
        "## Demo: Build a Predictive Regression Model for Housing Price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LXn1ZVJIn_k"
      },
      "source": [
        "### Step 1 Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns18cp-nepZ7"
      },
      "source": [
        "import pandas as pd\n",
        "dataset_path = \"https://raw.githubusercontent.com/tertiarycourses/datasets/master/boston.csv\"                     \n",
        "dataset = pd.read_csv(dataset_path)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZRgXF8U5V-x"
      },
      "source": [
        "dataset = dataset.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as-f5S9I5YN7"
      },
      "source": [
        "x_train = dataset.sample(frac=0.7,random_state=0)\n",
        "x_test = dataset.drop(x_train.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9De5i0275Zzt"
      },
      "source": [
        "y_train = x_train.pop('medv')\n",
        "y_test = x_test.pop('medv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uO1NVtF5bOH"
      },
      "source": [
        "x_train = (x_train - x_train.mean())/(x_train.max()-x_train.min())\n",
        "x_test = (x_test - x_test.mean())/(x_test.max()-x_test.min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxTY-di5NHzS"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrMx0mbe6wu5"
      },
      "source": [
        "import torch\n",
        "\n",
        "x_train = torch.Tensor(x_train.values)\n",
        "y_train = torch.Tensor(y_train.values)\n",
        "\n",
        "x_test = torch.Tensor(x_test.values)\n",
        "y_test = torch.Tensor(y_test.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImdIPcDcGFAr"
      },
      "source": [
        "y_train = torch.unsqueeze(y_train, dim=1) \n",
        "y_test = torch.unsqueeze(y_test, dim=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yPMcsa5-HCs"
      },
      "source": [
        "x_train.shape, y_train.shape,x_test.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So5PZ3YhIwzL"
      },
      "source": [
        "### Step 2 Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItjYrsuu5dGc"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 32\n",
        "L2 = 64\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.fc1 = nn.Linear(13,L1)     \n",
        "        self.fc2 = nn.Linear(L1,L2)\n",
        "        self.fc3 = nn.Linear(L2,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = self.fc3(x)             \n",
        "        return x\n",
        "\n",
        "model = Model() \n",
        "print(model) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9wclFVOI01a"
      },
      "source": [
        "### Step 3 Define the Loss Function and Optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3U04ACC6GNB"
      },
      "source": [
        "#  Loss function\n",
        "\n",
        "criterion = nn.MSELoss()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OilVgBn66G9F"
      },
      "source": [
        "# Optimizer\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBw7dlX6JPVG"
      },
      "source": [
        "### Step 4 Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09vfhfgp6aI8"
      },
      "source": [
        "for i in range(1000):\n",
        "\n",
        "\t# Model prediction\n",
        "    yhat = model(x_train)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = criterion(yhat, y_train)\n",
        "\n",
        "    # Compute gradients and update parameters     \n",
        "    optimizer.zero_grad()   \n",
        "    loss.backward()         \n",
        "    optimizer.step()       \n",
        "\n",
        "    if i%50==0: print(f'step {i}. loss = {loss.item():0.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjw3w75aLzN9"
      },
      "source": [
        "### Step 5 Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEJZB0zH6l8_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(y_test, model(x_test).data)\n",
        "plt.xlabel('True Values [Housing Price]')\n",
        "plt.ylabel('Predictions [Housing Price]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "plt.plot([0, 100], [0, 100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw3KpSEGA7Ty"
      },
      "source": [
        "y_hat.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XYniWyCOpji"
      },
      "source": [
        "## Save and Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkn0gAOtFiL1"
      },
      "source": [
        "torch.save(model,'./regression.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjuqTi1JNa7F"
      },
      "source": [
        "new_model=torch.load('./regression.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9OdIbhTOTcE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(y_test, new_model(x_test).data)\n",
        "plt.xlabel('True Values [Housing Price]')\n",
        "plt.ylabel('Predictions [Housing Price]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "plt.plot([0, 100], [0, 100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvelV5hrO2kI"
      },
      "source": [
        "## Activity: Predictive Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04GMNiP-P5jD"
      },
      "source": [
        "### Step 1 Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGjfmx_YOW50"
      },
      "source": [
        "import pandas as pd\n",
        "dataset_path = \"https://raw.githubusercontent.com/tertiarycourses/datasets/master/iris.csv\"\n",
        "                     \n",
        "dataset = pd.read_csv(dataset_path)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD3hZcxpO7zp"
      },
      "source": [
        "dataset = dataset.dropna()\n",
        "dataset.pop('species')\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHkS-SueO8Jl"
      },
      "source": [
        "x_train = dataset.sample(frac=0.7,random_state=0)\n",
        "x_test = dataset.drop(x_train.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUPBVmV5O_9c"
      },
      "source": [
        "y_train = x_train.pop('sepal_width')\n",
        "y_test = x_test.pop('sepal_width')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCqBnnnpPHx0"
      },
      "source": [
        "x_train = (x_train - x_train.mean())/(x_train.max()-x_train.min())\n",
        "x_test = (x_test - x_test.mean())/(x_test.max()-x_test.min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGi64hZEPJqI"
      },
      "source": [
        "import torch\n",
        "\n",
        "x_train = torch.Tensor(x_train.values)\n",
        "y_train = torch.Tensor(y_train.values)\n",
        "\n",
        "x_test = torch.Tensor(x_test.values)\n",
        "y_test = torch.Tensor(y_test.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey0ZAW46PRN6"
      },
      "source": [
        "y_train = torch.unsqueeze(y_train, dim=1) \n",
        "y_test = torch.unsqueeze(y_test, dim=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtU9lexgPTCG"
      },
      "source": [
        "x_train.shape, y_train.shape,x_test.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wNP54DhQF0_"
      },
      "source": [
        "### Step 2 Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L2u3hPLPVEa"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 32\n",
        "L2 = 64\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.fc1 = nn.Linear(3,L1)     \n",
        "        self.fc2 = nn.Linear(L1,L2)\n",
        "        self.fc3 = nn.Linear(L2,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = self.fc3(x)             \n",
        "        return x\n",
        "\n",
        "model = Model() \n",
        "print(model) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhE7L8cvQPz2"
      },
      "source": [
        "### Step 3 Define the Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKRPul_HPZ6x"
      },
      "source": [
        "#  Loss function\n",
        "\n",
        "criterion = nn.MSELoss()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIPapFsePen0"
      },
      "source": [
        "# Optimizer\n",
        "\n",
        "learning_rate = 0.0001\n",
        "\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZJ4DgwtQUhK"
      },
      "source": [
        "### Step 4 Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsR_ml9SPhKZ"
      },
      "source": [
        "for i in range(1000):\n",
        "\n",
        "\t# Model prediction\n",
        "    yhat = model(x_train)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = criterion(yhat, y_train)\n",
        "\n",
        "    # Compute gradients and update parameters     \n",
        "    optimizer.zero_grad()   \n",
        "    loss.backward()         \n",
        "    optimizer.step()       \n",
        "\n",
        "    if i%50==0: print(f'step {i}. loss = {loss.item():0.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIpnqun-Qhcw"
      },
      "source": [
        "### Step 5 Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQRpr1_0Pjhj"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(y_test, model(x_test).data)\n",
        "plt.xlabel('True Values Sepal Width')\n",
        "plt.ylabel('Predictions Sepal Width')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "plt.plot([0, 100], [0, 100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xVeTe7aRx89"
      },
      "source": [
        "# Topic 3 Neural Network for Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cTyqPnmcBzS"
      },
      "source": [
        "## MNIST Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f9dWS4jiwLT"
      },
      "source": [
        "### Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHeyy3IoSZPZ"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "mean, std = (0.5,), (0.5,)\n",
        "\n",
        "# Create a transform and normalise data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean, std)\n",
        "                              ])\n",
        "\n",
        "# Download MNIST training dataset and load training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download MNIST test dataset and load test data\n",
        "testset = datasets.MNIST('~/.pytorch/MNIST/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FLCSN0d5D-x"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image,label = next(iter(trainloader))\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.imshow(image[i][0], cmap='gray')\n",
        "  plt.title(\"Ground Truth: {}\".format(label[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9NXzwwdi3Lb"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWdKLPJWYRpF"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 32\n",
        "L2 = 64\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.fc1 = nn.Linear(784,L1)     \n",
        "        self.fc2 = nn.Linear(L1,L2)\n",
        "        self.fc3 = nn.Linear(L2,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = self.fc3(x)   \n",
        "        return x\n",
        "\n",
        "model = Model()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "model.to(device) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFJS0E2ql0aW"
      },
      "source": [
        "# Alternative way to define the model\n",
        "# Step 2: Define Model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 32\n",
        "L2 = 64\n",
        "model = nn.Sequential(nn.Flatten(),\n",
        "                      nn.Linear(784, L1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(L1, L2),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(L2, 10))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y25GhcXtVq3f"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "model.to(device) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_zYqeegi-i6"
      },
      "source": [
        "### Define the Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5yE7i5cYRwD"
      },
      "source": [
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb7yPy8ui_7y"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3C_r1aUnxd4"
      },
      "source": [
        "num_epochs = 10\n",
        "train_tracker, test_tracker, accuracy_tracker = [], [], []\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch, (X, y) in enumerate(trainloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        yhat = model(X)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(yhat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    train_tracker.append(train_loss/len(trainloader))\n",
        "    print(f\"Epoch({i+1}/{num_epochs}) | Training loss: {train_loss/len(trainloader)} | \",end='')\n",
        "    \n",
        "    test_loss = 0\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch, (X, y) in enumerate(testloader,1):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        yhat = model(X)\n",
        "        loss = criterion(yhat,y)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        \n",
        "        _, pred = torch.max(yhat.data, 1)\n",
        "        total += y.size(0)\n",
        "        num_correct += (pred == y.data).sum()\n",
        "\n",
        "    test_tracker.append(test_loss/len(testloader))\n",
        "    print(f\"Test loss: {test_loss/len(testloader)} | \", end='')\n",
        "\n",
        "    accuracy_tracker.append(num_correct/total)\n",
        "    print(f'Accuracy : {num_correct/total}')        \n",
        "\n",
        "print(f'\\nNumber correct : {num_correct}, Total : {total}')\n",
        "print(f'Accuracy: {num_correct * 100 / total}% ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYWNEQzzjDdx"
      },
      "source": [
        "### Step 5 Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6VyVWK-sGkq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_tracker, label='Training loss')\n",
        "plt.plot(test_tracker, label='Test loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(accuracy_tracker, label='Test accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7wv4vI5eZjO"
      },
      "source": [
        "## Activity: Fashion MNIST Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n5DkX1IIDOV"
      },
      "source": [
        "### Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWqDZIRWedpx"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "mean, std = (0.5,), (0.5,)\n",
        "\n",
        "# Create a transform and normalise data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean, std)\n",
        "                              ])\n",
        "\n",
        "# Download FMNIST training dataset and load training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download FMNIST test dataset and load test data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq5G4aLQuGgp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image,label = next(iter(trainloader))\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.imshow(image[i][0], cmap='gray')\n",
        "  plt.title(\"Ground Truth: {}\".format(label[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD736TNIIAkx"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgjTa0Qserd_"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 32\n",
        "L2 = 64\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.fc1 = nn.Linear(784,L1)     \n",
        "        self.fc2 = nn.Linear(L1,L2)\n",
        "        self.fc3 = nn.Linear(L2,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = F.relu(self.fc2(x)) \n",
        "        x = self.fc3(x)   \n",
        "        return x\n",
        "\n",
        "model = Model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6NRPidnXmaH"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "model.to(device) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UGAZ04LIGaM"
      },
      "source": [
        "### Define the loss function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlUfPP3Ee3ee"
      },
      "source": [
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F4s6VqdaGmT"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "306NmZEaUbIu"
      },
      "source": [
        "num_epochs = 10\n",
        "train_tracker, test_tracker, accuracy_tracker = [], [], []\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch, (X, y) in enumerate(trainloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        yhat = model(X)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(yhat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    train_tracker.append(train_loss/len(trainloader))\n",
        "    print(f\"Epoch({i+1}/{num_epochs}) | Training loss: {train_loss/len(trainloader)} | \",end='')\n",
        "    \n",
        "    test_loss = 0\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch, (X, y) in enumerate(testloader,1):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        yhat = model(X)\n",
        "        loss = criterion(yhat,y)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        \n",
        "        _, pred = torch.max(yhat.data, 1)\n",
        "        total += y.size(0)\n",
        "        num_correct += (pred == y.data).sum()\n",
        "\n",
        "    test_tracker.append(test_loss/len(testloader))\n",
        "    print(f\"Test loss: {test_loss/len(testloader)} | \", end='')\n",
        "\n",
        "    accuracy_tracker.append(num_correct/total)\n",
        "    print(f'Accuracy : {num_correct/total}')        \n",
        "    \n",
        "print(f'\\nNumber correct : {num_correct}, Total : {total}')\n",
        "print(f'Accuracy of the model after 30 epochs on the 10000 test images: {num_correct * 100 / total}% ')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j3uo7mRHyBU"
      },
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HGNdB4pdE9R"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_tracker, label='Training loss')\n",
        "plt.plot(test_tracker, label='Test loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(accuracy_tracker, label='Test accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kze0f3VXjIFa"
      },
      "source": [
        "# Topic 4 Convolutional Neural Network for Pattern Recognition\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfVmcqnUdW43"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBkzWrbudI8V"
      },
      "source": [
        "import torch\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cezdjeMTu45G"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "mean, std = (0.5,), (0.5,)\n",
        "\n",
        "# Create a transform and normalise data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean, std)\n",
        "                              ])\n",
        "\n",
        "# Download MNIST training dataset and load training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download MNIST test dataset and load test data\n",
        "testset = datasets.MNIST('~/.pytorch/MNIST/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzufVUondZt4"
      },
      "source": [
        "## Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaur5V-uTpQc"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 16\n",
        "L2 = 32\n",
        "L3 = 128\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,L1,3,1,1)\n",
        "        self.conv2 = nn.Conv2d(L1,L2,3,1,1)\n",
        "        self.fc1 = nn.Linear(L2*7*7,L3)\n",
        "        self.fc2 = nn.Linear(L3, 10)     \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))              \n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = Model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lppROK-HpB3L"
      },
      "source": [
        "# Alternative way to define the model\n",
        "# Step 2: Define Model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 16\n",
        "L2 = 32\n",
        "L3 = 128\n",
        "\n",
        "model = nn.Sequential(nn.Conv2d(1,L1,3,1,1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.MaxPool2d(2),\n",
        "                      nn.Conv2d(L1,L2,3,1,1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.MaxPool2d(2),\n",
        "                      nn.Flatten(),\n",
        "                      nn.Linear(L2*7*7,L3),\n",
        "                      nn.Linear(L3, 10))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9x9EeyPErpr"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPipBlT6bC1i"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LMjouRZdb_o"
      },
      "source": [
        "## Define Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8lKoivsVE2a"
      },
      "source": [
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB-1pch4dehW"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9yMLMhJUqms"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "num_epochs = 10\n",
        "train_tracker, test_tracker, accuracy_tracker = [], [], []\n",
        "\n",
        "for i in tqdm(range(num_epochs)):\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch, (X, y) in enumerate(trainloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        yhat = model(X)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(yhat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    train_tracker.append(train_loss/len(trainloader))\n",
        "    print(f\"Epoch({i+1}/{num_epochs}) | Training loss: {train_loss/len(trainloader)} | \",end='')\n",
        "    \n",
        "    test_loss = 0\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch, (X, y) in enumerate(testloader,1):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        yhat = model(X)\n",
        "        loss = criterion(yhat,y)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        \n",
        "        _, pred = torch.max(yhat.data, 1)\n",
        "        total += y.size(0)\n",
        "        num_correct += (pred == y.data).sum()\n",
        "\n",
        "    test_tracker.append(test_loss/len(testloader))\n",
        "    print(f\"Test loss: {test_loss/len(testloader)} | \", end='')\n",
        "    \n",
        "    accuracy_tracker.append(num_correct/total)\n",
        "    print(f'Accuracy : {num_correct/total}')        \n",
        "print(f'\\nNumber correct : {num_correct}, Total : {total}')\n",
        "print(f'Accuracy of the model after 30 epochs on the 10000 test images: {num_correct * 100 / total}% ')\n",
        "           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxGU64eydj2E"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6f0sEAbLw6B"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_tracker, label='Training loss')\n",
        "plt.plot(test_tracker, label='Test loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(accuracy_tracker, label='Test accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RIGyBLzdtGt"
      },
      "source": [
        "## Activity: CNN on CIFAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koAag2qVd3S6"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "mean = [0.5, 0.5, 0.5]\n",
        "std = [0.5, 0.5, 0.5]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "    ])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='~/.pytorch/CIFAR10',train=True, download=True,transform=transform)\n",
        "testset = datasets.CIFAR10(root='~/.pytorch/CIFAR10',train=False, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNUZsHqOd60G"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "\n",
        "L1 = 16\n",
        "L2 = 32\n",
        "L3 = 128\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,L1,3,1,1)\n",
        "        self.conv2 = nn.Conv2d(L1,L2,3,1,1)\n",
        "        self.fc1 = nn.Linear(L2*8*8,L3)\n",
        "        self.fc2 = nn.Linear(L3, 10)     \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view( x.size(0),-1) \n",
        "        x = F.relu(self.fc1(x))              \n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyXCRcqscmWJ"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcQiiffzd_WG"
      },
      "source": [
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()                       \n",
        "\n",
        "# Optmizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbJoRh0ueKHo"
      },
      "source": [
        "num_epochs = 10\n",
        "train_tracker, test_tracker, accuracy_tracker = [], [], []\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch, (X, y) in enumerate(trainloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        yhat = model(X)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(yhat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    train_tracker.append(train_loss/len(trainloader))\n",
        "    print(f\"Epoch({i+1}/{num_epochs}) | Training loss: {train_loss/len(trainloader)} | \",end='')\n",
        "    \n",
        "    test_loss = 0\n",
        "    num_correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch, (X, y) in enumerate(testloader,1):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        yhat = model(X)\n",
        "        loss = criterion(yhat,y)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        \n",
        "        _, pred = torch.max(yhat.data, 1)\n",
        "        total += y.size(0)\n",
        "        num_correct += (pred == y.data).sum()\n",
        "\n",
        "    test_tracker.append(test_loss/len(testloader))\n",
        "    print(f\"Test loss: {test_loss/len(testloader)} | \", end='')\n",
        "\n",
        "    accuracy_tracker.append(num_correct/total)\n",
        "    print(f'Accuracy : {num_correct/total}')   \n",
        "\n",
        "print(f'\\nNumber correct : {num_correct}, Total : {total}')\n",
        "print(f'Accuracy of the model after 30 epochs on the 10000 test images: {num_correct * 100 / total}% ')\n",
        "           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-Qq3sQdeNpS"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_tracker, label='Training loss')\n",
        "plt.plot(test_tracker, label='Test loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(accuracy_tracker, label='Test accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rLINxWGbzTy"
      },
      "source": [
        "# Topic 5 Data Visualization with Tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghNigpqOb5Bx"
      },
      "source": [
        "## Fashion MNIST Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fp0Z7zEbz0a"
      },
      "source": [
        "# imports\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# transforms\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# datasets\n",
        "trainset = torchvision.datasets.FashionMNIST('./data',\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=transform)\n",
        "testset = torchvision.datasets.FashionMNIST('./data',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=transform)\n",
        "\n",
        "# dataloaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                        shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                        shuffle=False, num_workers=2)\n",
        "\n",
        "# constant for classes\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
        "\n",
        "# helper function to show an image\n",
        "# (used in the `plot_classes_preds` function below)\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHZn7WalcHKu"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOEuCV5icMuD"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8c5XfrFcUOR"
      },
      "source": [
        "### Setup Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfOcGNwacO-b"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq042r9OeIig"
      },
      "source": [
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=True)\n",
        "\n",
        "# write to tensorboard\n",
        "writer.add_image('four_fashion_mnist_images', img_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjTvb2bGebB_"
      },
      "source": [
        "### Show the data on Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSTlwhjgeI5_"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQOJm-IYeeD0"
      },
      "source": [
        "%tensorboard --logdir=runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJYmebb6eiPC"
      },
      "source": [
        "### Show Model Architecture on Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0MQTFI8egeE"
      },
      "source": [
        "writer.add_graph(net, images)\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNsM_URxepFQ"
      },
      "source": [
        "%tensorboard --logdir=runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcqNB0_Beq2h"
      },
      "source": [
        "# helper functions\n",
        "\n",
        "def images_to_probs(net, images):\n",
        "    '''\n",
        "    Generates predictions and corresponding probabilities from a trained\n",
        "    network and a list of images\n",
        "    '''\n",
        "    output = net(images)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, preds_tensor = torch.max(output, 1)\n",
        "    preds = np.squeeze(preds_tensor.numpy())\n",
        "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
        "\n",
        "\n",
        "def plot_classes_preds(net, images, labels):\n",
        "    '''\n",
        "    Generates matplotlib Figure using a trained network, along with images\n",
        "    and labels from a batch, that shows the network's top prediction along\n",
        "    with its probability, alongside the actual label, coloring this\n",
        "    information based on whether the prediction was correct or not.\n",
        "    Uses the \"images_to_probs\" function.\n",
        "    '''\n",
        "    preds, probs = images_to_probs(net, images)\n",
        "    # plot the images in the batch, along with predicted and true labels\n",
        "    fig = plt.figure(figsize=(12, 48))\n",
        "    for idx in np.arange(4):\n",
        "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
        "        matplotlib_imshow(images[idx], one_channel=True)\n",
        "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
        "            classes[preds[idx]],\n",
        "            probs[idx] * 100.0,\n",
        "            classes[labels[idx]]),\n",
        "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
        "    return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjDtM8B0ezff"
      },
      "source": [
        "### Show the Training Loss on Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4Pw3Varew0B"
      },
      "source": [
        "running_loss = 0.0\n",
        "for epoch in range(1):  # loop over the dataset multiple times\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
        "\n",
        "            # ...log the running loss\n",
        "            writer.add_scalar('training loss',\n",
        "                            running_loss / 1000,\n",
        "                            epoch * len(trainloader) + i)\n",
        "\n",
        "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
        "            # random mini-batch\n",
        "            writer.add_figure('predictions vs. actuals',\n",
        "                            plot_classes_preds(net, inputs, labels),\n",
        "                            global_step=epoch * len(trainloader) + i)\n",
        "            running_loss = 0.0\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3ox6zjGe3Z5"
      },
      "source": [
        "%tensorboard --logdir=runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpQhXfewe9mJ"
      },
      "source": [
        "### Show the Precison Recall Curves on Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qTQ2qcRe6Ik"
      },
      "source": [
        "# takes ~10 seconds to run\n",
        "class_probs = []\n",
        "class_preds = []\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        output = net(images)\n",
        "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
        "        _, class_preds_batch = torch.max(output, 1)\n",
        "\n",
        "        class_probs.append(class_probs_batch)\n",
        "        class_preds.append(class_preds_batch)\n",
        "\n",
        "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
        "test_preds = torch.cat(class_preds)\n",
        "\n",
        "# helper function\n",
        "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
        "    '''\n",
        "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
        "    precision-recall curve\n",
        "    '''\n",
        "    tensorboard_preds = test_preds == class_index\n",
        "    tensorboard_probs = test_probs[:, class_index]\n",
        "\n",
        "    writer.add_pr_curve(classes[class_index],\n",
        "                        tensorboard_preds,\n",
        "                        tensorboard_probs,\n",
        "                        global_step=global_step)\n",
        "    writer.close()\n",
        "\n",
        "# plot all the pr curves\n",
        "for i in range(len(classes)):\n",
        "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NTIXCykfB6j"
      },
      "source": [
        "%tensorboard --logdir=runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IhLzQOafGoB"
      },
      "source": [
        "## Activity: MNIST on Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml_KaB88fDyc"
      },
      "source": [
        "# imports\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# transforms\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# datasets\n",
        "trainset = torchvision.datasets.MNIST('./data',\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=transform)\n",
        "testset = torchvision.datasets.MNIST('./data',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=transform)\n",
        "\n",
        "# dataloaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                        shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                        shuffle=False, num_workers=2)\n",
        "\n",
        "# constant for classes\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
        "\n",
        "# helper function to show an image\n",
        "# (used in the `plot_classes_preds` function below)\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNRi9nUqfLHE"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUWyAKjQfNzY"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeLsYef6fPlm"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs2/mnist_experiment_1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr-DDZdwfRIH"
      },
      "source": [
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=True)\n",
        "\n",
        "# write to tensorboard\n",
        "writer.add_image('runs2/four_mnist_images', img_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBQaHn7GfTJ6"
      },
      "source": [
        "%tensorboard --logdir=runs2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlgpgRNPfU1v"
      },
      "source": [
        "running_loss = 0.0\n",
        "for epoch in range(1):  # loop over the dataset multiple times\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
        "\n",
        "            # ...log the running loss\n",
        "            writer.add_scalar('runs2/training loss',\n",
        "                            running_loss / 1000,\n",
        "                            epoch * len(trainloader) + i)\n",
        "\n",
        "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
        "            # random mini-batch\n",
        "            writer.add_figure('predictions vs. actuals',\n",
        "                            plot_classes_preds(net, inputs, labels),\n",
        "                            global_step=epoch * len(trainloader) + i)\n",
        "            running_loss = 0.0\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO74wBAFfYTj"
      },
      "source": [
        "%tensorboard --logdir=runs2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rMnnmQKfaez"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}